{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec89e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd0111",
   "metadata": {},
   "source": [
    "### 注意不管是LayerNorm还是RMSNorm，求均值、方差等计算方式时，都是针对最后一维度。就相当于有batch_size*seq_len个样本，每个样本要保持均值为0方差为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccb1c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现LayerNorm\n",
    "class CustomLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init_()\n",
    "        if isinstance(normalized_shape, int):\n",
    "            normalized_shape = (normalized_shape,)\n",
    "        self.normalized_shape = torch.Size(normalized_shape)\n",
    "        self.eps = eps\n",
    "\n",
    "        # 创建可学习的缩放参数gamma和偏移参数beta\n",
    "        # nn.Parameter 会将它们注册为模型的参数，这样在训练时可以被优化器更新\n",
    "        self.gamma = nn.Parameter(torch.ones(self.normalized_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(self.normalized_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        dims = tuple(range(x.dim() - len(self.normalized_shape), x.dim()))\n",
    "        print(\"dims:\", dims)\n",
    "        # 计算均值和方差\n",
    "        mean = x.mean(dims, keepdim=True)\n",
    "        var = x.var(dims, keepdim=True, unbiased=False)\n",
    "        # 归一化\n",
    "        x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        # 缩放和偏移\n",
    "        output = self.gamma * x_normalized + self.beta\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad77c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现RMSNorm\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.eps = eps\n",
    "        # 创建可学习的缩放参数gamma\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        # 实现x / sqrt( (1/n) * sum(x_i^2) + eps )\n",
    "        # torch.rsqrt()计算1/sqrt()\n",
    "        rms = torch.rsqrt(x.pow(2).mean(dim=-1, keepdim=True) + self.eps)\n",
    "        return x * rms\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self._norm(x)\n",
    "        # 缩放gamma\n",
    "        return output * self.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d962be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "embedding_dim = x.shape[-1]\n",
    "\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "output = layer_norm(x)\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "rms_norm = RMSNorm(embedding_dim)\n",
    "output = rms_norm(x)\n",
    "\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
